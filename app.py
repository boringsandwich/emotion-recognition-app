import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import os
import random
import glob
from PIL import Image

# Importy do Twojego modelu (TensorFlow)
import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Import do nowej funkcji kamery (DeepFace)
from deepface import DeepFace

# --- KONFIGURACJA STRONY ---
st.set_page_config(page_title="System Analizy Emocji", layout="wide")

# ==========================================
# KONFIGURACJA 1: TW√ìJ MODEL (BADANIA)
# ==========================================
MODEL_PATH = 'moj_model_fer.h5'
DATASET_TEST_PATH = './dane_fer/test'
DEFAULT_USER_FOLDER = 'test_real'

CLASSES = ['angry', 'happy', 'sad']
TRANSLATION = {'angry': 'Z≈ÅO≈öƒÜ', 'happy': 'RADO≈öƒÜ', 'sad': 'SMUTEK'}
COLORS = {'angry': '#FF4B4B', 'happy': '#2ECC71', 'sad': '#3498DB'}

# ==========================================
# KONFIGURACJA 2: KAMERA (DEEPFACE)
# ==========================================
# Tutaj definiujemy TYLKO te emocje, kt√≥re nas interesujƒÖ
TARGET_EMOTIONS = {
    'angry': 'Z≈ÅO≈öƒÜ',
    'happy': 'RADO≈öƒÜ',
    'sad': 'SMUTEK'
}
# Kolory dla wykres√≥w w trybie DeepFace
DEEPFACE_COLORS_HEX = {
    'Z≈ÅO≈öƒÜ': '#FF4B4B',
    'RADO≈öƒÜ': '#2ECC71',
    'SMUTEK': '#3498DB'
}


# --- FUNKCJE POMOCNICZE (TW√ìJ MODEL) ---

@st.cache_resource
def load_ai_model():
    if not os.path.exists(MODEL_PATH):
        return None
    return tf.keras.models.load_model(MODEL_PATH)


def preprocess_image(image_path):
    try:
        # Tw√≥j model wymaga 48x48 grayscale
        img = load_img(image_path, color_mode='grayscale', target_size=(48, 48))
        img_array = img_to_array(img)
        img_array /= 255.0
        return np.expand_dims(img_array, axis=0)
    except Exception:
        return None


def get_dataset_images(limit=None):
    search_path = os.path.join(DATASET_TEST_PATH, '**', '*.jpg')
    found_files = glob.glob(search_path, recursive=True)
    if not found_files: return []
    if limit is not None and len(found_files) > limit:
        return random.sample(found_files, limit)
    return found_files


# =========================================================
# G≈Å√ìWNY INTERFEJS (SELEKCJA TRYBU)
# =========================================================

st.sidebar.title("üéõÔ∏è Panel Sterowania")
app_mode = st.sidebar.selectbox(
    "Wybierz tryb aplikacji:",
    ["üìÇ Badanie (M√≥j Model - Orygina≈Ç)", "üì∑ Kamera (Live Foto - DeepFace)"]
)

# ---------------------------------------------------------
# TRYB 1: BADANIE (To jest Tw√≥j stary kod)
# ---------------------------------------------------------
if app_mode == "üìÇ Badanie (M√≥j Model - Orygina≈Ç)":

    st.title("üß† System Rozpoznawania Emocji (Tw√≥j Model)")

    # 1. ≈Åadowanie Modelu
    model = load_ai_model()

    if model is None:
        st.error(f"Nie znaleziono modelu '{MODEL_PATH}'. Uruchom najpierw trening (emotion.py)!")
        st.stop()

    st.sidebar.header("‚öôÔ∏è ≈πr√≥d≈Ço Danych")
    source_option = st.sidebar.radio(
        "SkƒÖd pobraƒá zdjƒôcia?",
        ("üìÇ W≈Çasny folder (test_real)", "üìö Zbi√≥r testowy (Dataset)")
    )

    image_paths = []
    current_source_name = ""

    # Logika wyboru plik√≥w
    if source_option == "üìÇ W≈Çasny folder (test_real)":
        folder_path = st.sidebar.text_input("≈öcie≈ºka do folderu:", value=DEFAULT_USER_FOLDER)
        current_source_name = "Moje zdjƒôcia"
        if os.path.exists(folder_path):
            files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            image_paths = [os.path.join(folder_path, f) for f in files]
        else:
            st.sidebar.warning("Folder nie istnieje.")

    else:  # Dataset
        current_source_name = "Zbi√≥r Testowy (Dataset)"
        if os.path.exists(DATASET_TEST_PATH):
            load_all = st.sidebar.checkbox("Wczytaj WSZYSTKIE dostƒôpne zdjƒôcia", value=False)
            if load_all:
                image_paths = get_dataset_images(limit=None)
                st.sidebar.warning(f"‚ö†Ô∏è Uwaga: Wczytano {len(image_paths)} zdjƒôƒá.")
            else:
                sample_size = st.sidebar.number_input("Liczba losowych zdjƒôƒá:", min_value=1, value=200, step=50)
                image_paths = get_dataset_images(limit=sample_size)
                st.sidebar.info(f"Pobrano losowe {len(image_paths)} zdjƒôƒá.")
        else:
            st.sidebar.error(f"Nie znaleziono folderu {DATASET_TEST_PATH}.")

    if not image_paths:
        st.warning("Brak zdjƒôƒá do analizy.")
        st.stop()

    # --- ANALIZA DANYCH ---
    session_key = f'analysis_{current_source_name}_{len(image_paths)}'

    if session_key not in st.session_state:
        st.session_state[session_key] = None

    if st.session_state[session_key] is None:
        progress_bar = st.progress(0)
        status_text = st.empty()
        results = []
        has_ground_truth = False
        total_imgs = len(image_paths)

        with st.spinner(f"Przetwarzanie {total_imgs} zdjƒôƒá Twoim modelem..."):
            for i, path in enumerate(image_paths):
                if i % (max(1, total_imgs // 20)) == 0:
                    progress_bar.progress(i / total_imgs)
                    status_text.text(f"Analiza obrazu {i + 1}/{total_imgs}")

                processed_img = preprocess_image(path)
                if processed_img is not None:
                    # Predykcja Twoim modelem
                    pred = model.predict(processed_img, verbose=0)[0]
                    idx = np.argmax(pred)
                    label = CLASSES[idx]
                    confidence = np.max(pred)

                    filename = os.path.basename(path)
                    parent_folder = os.path.basename(os.path.dirname(path))
                    true_label_eng = parent_folder if parent_folder in CLASSES else None
                    true_label_pl = TRANSLATION.get(true_label_eng, "-")

                    if true_label_eng: has_ground_truth = True

                    results.append({
                        "Plik": filename,
                        "Prawdziwa_Etykieta": true_label_pl,
                        "Wykryta_Emocja": TRANSLATION[label],
                        "Pewno≈õƒá": confidence,
                        "Raw_Angry": pred[0], "Raw_Happy": pred[1], "Raw_Sad": pred[2],
                        "≈öcie≈ºka": path,
                        "Poprawne": true_label_pl == TRANSLATION[label] if true_label_eng else None
                    })
            progress_bar.progress(1.0)
            status_text.empty()

        st.session_state[session_key] = pd.DataFrame(results)
        st.session_state[f"{session_key}_has_gt"] = has_ground_truth

    df = st.session_state[session_key]
    has_gt = st.session_state.get(f"{session_key}_has_gt", False)

    # --- ZAK≈ÅADKI ---
    tab1, tab2, tab3 = st.tabs(["üìä Raporty i Statystyki", "üîç PrzeglƒÖdarka (Interakcja)", "üßÆ Wnioskowanie Bayesowskie"])

    # TAB 1: RAPORTY
    with tab1:
        st.header(f"Raport dla: {current_source_name}")
        with st.expander("üìà Zobacz historiƒô treningu"):
            if os.path.exists("wykresy_treningu.png"):
                st.image("wykresy_treningu.png", use_container_width=True)
            else:
                st.warning("Brak pliku wykresy_treningu.png")

        col1, col2 = st.columns(2)
        with col1:
            fig_pie = px.pie(df, names='Wykryta_Emocja', title='Rozk≈Çad Wykrytych Emocji',
                             color='Wykryta_Emocja', color_discrete_map={v: COLORS[k] for k, v in TRANSLATION.items()})
            st.plotly_chart(fig_pie, use_container_width=True)
        with col2:
            avg_conf = df.groupby('Wykryta_Emocja')['Pewno≈õƒá'].mean().reset_index()
            fig_bar = px.bar(avg_conf, x='Wykryta_Emocja', y='Pewno≈õƒá', title='≈örednia Pewno≈õƒá',
                             color='Wykryta_Emocja', color_discrete_map={v: COLORS[k] for k, v in TRANSLATION.items()})
            fig_bar.update_yaxes(range=[0, 1])
            st.plotly_chart(fig_bar, use_container_width=True)

        st.dataframe(df[['Plik', 'Prawdziwa_Etykieta', 'Wykryta_Emocja', 'Pewno≈õƒá']], use_container_width=True)

    # TAB 2: PRZEGLƒÑDARKA
    with tab2:
        st.header("Interaktywna PrzeglƒÖdarka")
        df_sorted = df.sort_values(by=['Poprawne', 'Pewno≈õƒá'], ascending=[False, False], na_position='last')

        c1, c2 = st.columns(2)
        target = c1.selectbox("Filtruj po emocji:", ["Wszystkie"] + list(TRANSLATION.values()))
        amount = c2.slider("Liczba zdjƒôƒá:", 1, len(df), min(20, len(df)))

        if target == "Wszystkie":
            filtered_df = df_sorted.head(amount)
        else:
            filtered_df = df_sorted[df_sorted['Wykryta_Emocja'] == target].head(amount)

        cols = st.columns(5)
        for index, row in filtered_df.iterrows():
            with cols[index % 5]:
                st.image(row['≈öcie≈ºka'], use_container_width=True)
                color_style = "green" if row['Poprawne'] else "red"
                if row['Prawdziwa_Etykieta'] == "-": color_style = "black"
                st.markdown(f"**{row['Wykryta_Emocja']}** ({row['Pewno≈õƒá']:.0%})", unsafe_allow_html=True)

    # TAB 3: BAYES
    with tab3:
        st.header("Eksperyment: Wnioskowanie Bayesowskie")
        col_left, col_right = st.columns([1, 2])
        with col_left:
            sel_file = st.selectbox("Wybierz zdjƒôcie:", df['Plik'])
            row_data = df[df['Plik'] == sel_file].iloc[0]
            st.image(row_data['≈öcie≈ºka'], width=200)

            st.markdown("### Kontekst (Prior)")
            p_ang = st.slider("Z≈Ço≈õƒá (Kontekst)", 0.0, 1.0, 0.33)
            p_hap = st.slider("Rado≈õƒá (Kontekst)", 0.0, 1.0, 0.33)
            p_sad = st.slider("Smutek (Kontekst)", 0.0, 1.0, 0.33)

            priors = np.array([p_ang, p_hap, p_sad])
            if priors.sum() == 0: priors = np.ones(3)
            priors /= priors.sum()

        with col_right:
            likelihood = np.array([row_data['Raw_Angry'], row_data['Raw_Happy'], row_data['Raw_Sad']])
            posterior = likelihood * priors
            posterior /= posterior.sum()

            fig = go.Figure()
            emotions_list = list(TRANSLATION.values())
            fig.add_trace(go.Bar(x=emotions_list, y=likelihood, name='Model (Oczy)'))
            fig.add_trace(go.Bar(x=emotions_list, y=posterior, name='Bayes (Oczy + Kontekst)'))
            st.plotly_chart(fig, use_container_width=True)
            st.success(f"Decyzja Bayesa: **{emotions_list[np.argmax(posterior)]}**")


# ---------------------------------------------------------
# TRYB 2: KAMERA (NOWO≈öƒÜ - DeepFace) - TYLKO SNAPSHOT
# ---------------------------------------------------------
elif app_mode == "üì∑ Kamera (Live Foto - DeepFace)":

    st.title("üì∑ Kamera (Analiza Emocji)")
    st.info(
        "Zr√≥b zdjƒôcie, aby model DeepFace przeanalizowa≈Ç emocje. Wynik zostanie ograniczony tylko do: Z≈Ço≈õƒá, Rado≈õƒá, Smutek.")

    img_buffer = st.camera_input("U≈õmiechnij siƒô!")

    if img_buffer is not None:
        # 1. Zapisz zdjƒôcie tymczasowo
        temp_filename = "temp_snap.jpg"
        with open(temp_filename, "wb") as f:
            f.write(img_buffer.getbuffer())

        col_res1, col_res2 = st.columns([1, 1.5])

        with col_res1:
            st.image(temp_filename, caption="Twoje zdjƒôcie", use_container_width=True)

        with col_res2:
            with st.spinner("Analiza w toku..."):
                try:
                    # DeepFace analizuje zdjƒôcie (wszystkie emocje)
                    # enforce_detection=False pozwala dzia≈Çaƒá nawet gdy twarz jest niewyra≈∫na
                    res = DeepFace.analyze(temp_filename, actions=['emotion'], enforce_detection=False)

                    if isinstance(res, list): res = res[0]

                    all_emotions = res['emotion']  # np. {'angry': 10, 'happy': 0.1, 'neutral': 80...}

                    # 2. FILTROWANIE (Kluczowy moment)
                    # Wybieramy tylko te 3 emocje, kt√≥re zdefiniowali≈õmy w TARGET_EMOTIONS
                    filtered_scores = {k: all_emotions.get(k, 0) for k in TARGET_EMOTIONS.keys()}

                    # Obliczamy sumƒô tych trzech, ≈ºeby przeliczyƒá procenty na nowo (≈ºeby sumowa≈Çy siƒô do 100%)
                    total_score = sum(filtered_scores.values())
                    if total_score == 0: total_score = 1  # Zabezpieczenie przez dzieleniem przez 0

                    # Normalizacja
                    normalized_scores = {k: (v / total_score) for k, v in filtered_scores.items()}

                    # Znalezienie zwyciƒôzcy
                    winner_key = max(normalized_scores, key=normalized_scores.get)
                    winner_pl = TARGET_EMOTIONS[winner_key]
                    winner_conf = normalized_scores[winner_key]

                    # Wy≈õwietlenie wyniku
                    st.success(f"Wykryta emocja: **{winner_pl}**")
                    st.metric("Pewno≈õƒá (w≈õr√≥d badanych 3)", f"{winner_conf:.1%}")

                    # Wykres
                    chart_data = pd.DataFrame({
                        'Emocja': [TARGET_EMOTIONS[k] for k in normalized_scores.keys()],
                        'Prawdopodobienstwo': list(normalized_scores.values())
                    })

                    fig = px.bar(chart_data, x='Emocja', y='Prawdopodobienstwo',
                                 title="Rozk≈Çad (Z≈Ço≈õƒá vs Rado≈õƒá vs Smutek)",
                                 color='Emocja', color_discrete_map=DEEPFACE_COLORS_HEX)
                    fig.update_yaxes(range=[0, 1])
                    st.plotly_chart(fig, use_container_width=True)

                except Exception as e:
                    st.error(f"WystƒÖpi≈Ç b≈ÇƒÖd analizy lub nie wykryto twarzy. Spr√≥buj ponownie.\nSzczeg√≥≈Çy: {e}")